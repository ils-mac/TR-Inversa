---
layout: default
title: Proyecto de Evaluaci贸n CONANP
parent: Semana 9
grand_parent: Unidad 3
nav_order: 4
---

# Proyecto de Evaluaci贸n: Logros - Proyecto Resiliencia (CONANP)

**Puntos:** 3

**Modalidad:** Individual

## Descripci贸n del Proyecto

En esta asignaci贸n, realizar谩s una evaluaci贸n profesional de calidad de traducci贸n del documento _Logros - Proyecto Resiliencia_ de CONANP utilizando Label Studio. Esta ser谩 tu primera evaluaci贸n completa aplicando el marco MQM que has estado estudiando durante el semestre.

Como aprendiste en la p谩gina anterior, ya has revisado el contexto del proyecto, entiendes la misi贸n de CONANP, y has documentado colaborativamente las especificaciones del proyecto en clase. Ahora aplicar谩s ese conocimiento para evaluar la calidad de la traducci贸n proporcionada.

### Prop贸sito de la Evaluaci贸n

Los datos etiquetados son un recurso importante para entrenar sistemas de inteligencia artificial generativa a realizar tareas de traducci贸n. A medida que el mundo se integra m谩s con IAG, un 谩rea de oportunidad es aplicar tus habilidades de traducci贸n a tareas de etiquetado de errores. La tipolog铆a de errores MQM es un enfoque basado en est谩ndares para etiquetar errores que se est谩 adoptando en toda la industria. Esta asignaci贸n te dar谩 experiencia tanto con MQM como con entornos profesionales de anotaci贸n de errores.

Un aspecto importante del etiquetado de errores es que las y los evaluadores identifican errores de manera inconsistente al principio. Por lo tanto, todas y todos trabajar谩n con el mismo texto, y m谩s adelante estudiar茅 c贸mo se superponeno nosus anotaciones. Las observaciones sobre la superposici贸n se utilizar谩n para ense帽arles sobre la armonizaci贸n del trabajo de etiquetado de errores en equipo.

### Documentos del Proyecto

- **Texto fuente**:
   - Texto completo: [CONANP_LogrosProyectoResiliencia.pdf](https://github.com/alainamb/uic_tr18-trad-inversa-es-en/blob/main/unidad3/semana9/referencias/CONANP_LogrosProyectoResiliencia.pdf)
   - Adaptado para esta tarea: [ResilenciaM茅xico_ES.pdf](https://github.com/alainamb/uic_tr18-trad-inversa-es-en/blob/main/unidad3/semana9/referencias/ResilenciaM茅xico_ES.pdf)
- **Texto meta**:
   - Texto completo: [CONANP_ProyectoResilienciaAcheivements.pdf](https://github.com/alainamb/uic_tr18-trad-inversa-es-en/blob/main/unidad3/semana9/referencias/CONANP_ProyectoResilienciaAcheivements.pdf)
   - Adaptado para esta tarea: [ResilenciaM茅xico_EN.pdf](https://github.com/alainamb/uic_tr18-trad-inversa-es-en/blob/main/unidad3/semana9/referencias/ResilenciaM茅xico_EN.pdf)
- **Especificaciones del proyecto**: Documento compartido completado en clase (disponible en Teams)

## Tu Asignaci贸n

### Paso 1: Revisar las Especificaciones

Antes de comenzar tu evaluaci贸n, revisa cuidadosamente el documento de especificaciones que desarrollaron colaborativamente en clase. Estas especificaciones son la base para determinar:
- Qu茅 constituye un error
- Qu茅 nivel de severidad es apropiado
- Qu茅 expectativas de calidad aplican para este proyecto espec铆fico

### Paso 2: Acceder al Proyecto en Label Studio

1. Inicia sesi贸n en Label Studio usando el enlace proporcionado en Teams
2. Localiza el proyecto: **"CONANP-Eval"**
3. Verifica que puedes ver el texto completo del documento

### Paso 3: Realizar la Evaluaci贸n Completa

Aplica la metodolog铆a que aprendiste durante las sesiones de entrenamiento tecnol贸gico y ling眉铆stico en clase. Tu evaluaci贸n debe incluir:

#### A. Anotaciones de Errores Individuales

Para cada error que identifiques, debes proporcionar:

1. **Selecci贸n precisa del texto**: Marca exactamente la parte problem谩tica del texto meta
2. **Dimensi贸n del error**: Selecciona la dimensi贸n apropiada (Terminolog铆a, Precisi贸n, Estilo, Convenciones Ling眉铆sticas, Convenciones Locales, Adecuaci贸n para la Audiencia, Otros)
3. **Tipo de error**: Especifica el tipo exacto dentro de la dimensi贸n
4. **Nivel de severidad**: Asigna neutral, menor, mayor o cr铆tica seg煤n el impacto
5. **Comentarios**: Explica por qu茅 es un error y, cuando sea posible, sugiere una correcci贸n

**Ejemplo de anotaci贸n completa:**
- **Texto marcado**: "tropicalization"
- **Dimensi贸n**: Terminolog铆a
- **Tipo**: T茅rmino incorrecto
- **Severidad**: Mayor
- **Comentario**: El t茅rmino establecido en ingl茅s para este fen贸meno es "tropicalization" no "tropicalization". Seg煤n las especificaciones, la terminolog铆a debe ser consistente con la literatura cient铆fica publicada.

#### B. Evaluaci贸n Hol铆stica del Documento

Despu茅s de identificar errores individuales, proporciona evaluaciones hol铆sticas:

1. **Correspondencia (1-4)**: 驴Qu茅 tan bien transmite el texto meta el significado del texto fuente?
   - 4 = Correspondencia excelente
   - 3 = Buena correspondencia
   - 2 = Correspondencia aceptable con problemas
   - 1 = Correspondencia pobre

2. **Legibilidad (1-4)**: 驴Qu茅 tan bien funciona el texto meta como documento independiente en ingl茅s?
   - 4 = Muy legible y natural
   - 3 = Generalmente legible
   - 2 = Legible pero con problemas
   - 1 = Dif铆cil de leer

3. **Comentarios hol铆sticos**: Proporciona observaciones sobre:
   - Patrones de error que notaste
   - Fortalezas generales de la traducci贸n
   - Problemas recurrentes
   - Efectividad general del documento

### Paso 4: Enviar Tu Evaluaci贸n

Una vez que hayas completado tu evaluaci贸n:
1. Revisa tu trabajo usando la lista de verificaci贸n (ver m谩s abajo)
2. Haz clic en **"Submit"** en Label Studio para entregar tu evaluaci贸n
3. No necesitas descargar ni subir ning煤n archivotu trabajo se guarda autom谩ticamente en Label Studio

### Paso 5: Reflexi贸n Escrita

Redacta una reflexi贸n cr铆tica (1-2 p谩rrafos) sobre tu experiencia trabajando con MQM en Label Studio. Tu reflexi贸n debe abordar:

**Preguntas obligatorias:**
- 驴Qu茅 funcion贸 bien para ti en este proceso?
- 驴Qu茅 desaf铆os encontraste al categorizar errores?
- 驴Qu茅 preguntas pendientes tienes sobre este trabajo?
- 驴Crees que tu trabajo ha mejorado esta semana? 驴Por qu茅 o por qu茅 no?

**Elementos de reflexi贸n cr铆tica** (incluye al menos 2):
- **An谩lisis de tu proceso**: 驴C贸mo abordaste la tarea? 驴Cambi贸 tu estrategia mientras trabajabas?
- **Dificultades espec铆ficas**: 驴Qu茅 tipos de errores fueron m谩s dif铆ciles de categorizar? 驴Por qu茅?
- **Desarrollo de habilidades**: 驴Qu茅 aprendiste sobre evaluaci贸n de traducci贸n que no sab铆as antes?
- **Aplicaci贸n futura**: 驴C贸mo influir谩 esta experiencia en tu trabajo como traductor/a?
- **Limitaciones reconocidas**: 驴D贸nde reconoces que tu evaluaci贸n podr铆a ser subjetiva o inconsistente?
- **Comparaci贸n con experiencias previas**: 驴En qu茅 se diferencia evaluar el trabajo de otros vs. traducir t煤 mismo/a?

**Entrega de la reflexi贸n**: Sube tu reflexi贸n como un documento en la tarea de Teams.

## Lista de Verificaci贸n Pre-Entrega

Antes de hacer clic en "Submit" en Label Studio y entregar tu reflexi贸n, verifica:

### Anotaciones en Label Studio
- [ ] He revisado el texto meta completo de manera sistem谩tica
- [ ] Cada error marcado tiene dimensi贸n, tipo de error, severidad Y comentarios
- [ ] Mis comentarios explican claramente por qu茅 algo es un error
- [ ] He considerado las especificaciones del proyecto al identificar errores
- [ ] No he marcado como errores las preferencias personales que no violan las especificaciones
- [ ] He proporcionado puntuaciones de correspondencia y legibilidad
- [ ] He escrito comentarios hol铆sticos sobre el documento completo
- [ ] He hecho clic en **"Submit"** en Label Studio

### Reflexi贸n Escrita
- [ ] Mi reflexi贸n tiene 1-2 p谩rrafos (150-300 palabras aproximadamente)
- [ ] He abordado las cuatro preguntas obligatorias
- [ ] He incluido al menos dos elementos de reflexi贸n cr铆tica
- [ ] Mi reflexi贸n va m谩s all谩 de observaciones superficiales
- [ ] He revisado ortograf铆a y gram谩tica
- [ ] He subido la reflexi贸n como comentario en Teams

## Criterios de Evaluaci贸n

### Puntuaci贸n Total: 3 puntos

| **Componente** | **Criterio** | **Puntuaci贸n** |
|----------------|--------------|----------------|
| **Completitud de anotaciones** (1 punto) | Excelente: Todas las anotaciones incluyen dimensi贸n, tipo, severidad y comentarios detallados; evaluaci贸n hol铆stica completa<br><br>Bueno: La mayor铆a de anotaciones est谩n completas; puede faltar informaci贸n ocasionalmente<br><br>Insuficiente: Muchas anotaciones incompletas o falta evaluaci贸n hol铆stica | 1 punto<br><br>0.5 puntos<br><br>0 puntos |
| **Precisi贸n de anotaciones** (1 punto) | Excelente: Identificaci贸n precisa de errores; categorizaci贸n apropiada seg煤n MQM; niveles de severidad bien justificados<br><br>Bueno: Generalmente preciso con algunos errores de categorizaci贸n; severidad mayormente apropiada<br><br>Insuficiente: Muchos errores mal categorizados; severidad inadecuada; confusi贸n con preferencias personales | 1 punto<br><br>0.5 puntos<br><br>0 puntos |
| **Reflexi贸n cr铆tica** (1 punto) | Excelente: Reflexi贸n profunda que demuestra pensamiento cr铆tico; aborda todas las preguntas; incluye an谩lisis significativo del proceso<br><br>Bueno: Reflexi贸n superficial pero completa; aborda las preguntas b谩sicamente; an谩lisis limitado<br><br>Insuficiente: Reflexi贸n muy breve o superficial; no aborda las preguntas; falta pensamiento cr铆tico | 1 punto<br><br>0.5 puntos<br><br>0 puntos |

### Notas Sobre la Evaluaci贸n

**Completitud**: Se eval煤a que todas las partes necesarias est茅n presentes. Una anotaci贸n sin comentarios, por ejemplo, no cuenta como completa.

**Precisi贸n**: Se eval煤a qu茅 tan bien aplicaste el marco MQM y las especificaciones del proyecto. No hay "respuestas correctas" absolutas, pero debe haber coherencia l贸gica entre lo que marcaste como error, c贸mo lo categorizaste, y las especificaciones del proyecto.

**Reflexi贸n cr铆tica**: Se eval煤a la profundidad de tu pensamiento, no solo el cumplimiento con el formato. Una reflexi贸n excelente demuestra que est谩s procesando activamente lo que aprendiste y c贸mo se relaciona con tu desarrollo profesional.

## Recursos de Apoyo

### Durante Tu Evaluaci贸n

- **Tipolog铆a MQM**: [themqm.org/the-mqm-typology](https://themqm.org/the-mqm-typology/)
- **Marco MQM del curso**: [Semana 4 - Marco MQM](../../unidad2/semana4/marco-mqm.md)
- **Ejemplos de errores MQM:** Documento compartido en Teams
- **Especificaciones del proyecto**: Documento compartido en Teams
- **Archivos de apoyo**: [Week 9 CONANP Evaluation Files en Teams](https://universidaduic.sharepoint.com/:f:/s/TR18TraduccinInversaAB-2025/EjRB12Q5ajpBoKAnOsCysPsBt3C0KSbFq2CIRdk5nG9RhA?e=5Sovch)

### Si Tienes Dudas

- **Durante la clase**: Pregunta a la profesora mientras trabajas
- **Fuera de la clase**: Env铆a un mensaje en Teams o correo electr贸nico
- **Dudas t茅cnicas con Label Studio**: Consulta la [Gu铆a de etiquetado](https://labelstud.io/guide/labeling)
- **Dudas sobre MQM**: Revisa la [p谩gina de MQM de la semana 4](../../unidad2/semana4/marco-mqm.md)

No dudes en pedir aclaracioneses mejor preguntar que hacer suposiciones incorrectas.

## Entrega

### Componentes Requeridos

1. **Evaluaci贸n en Label Studio**
   - Completada en el proyecto "CONANP-Eval with better UX"
   - Debe hacer clic en "Submit" para entregar
   - No hay archivo separado que descargar/subir

2. **Reflexi贸n escrita**
   - 1-2 p谩rrafos (150-300 palabras)
   - Subida como comentario en la tarea de Teams
   - Fecha l铆mite: [Fecha indicada en Teams]

### Formato de la Reflexi贸n

Tu reflexi贸n debe ser presentada profesionalmente:
- P谩rrafos bien organizados
- Ortograf铆a y gram谩tica correctas
- Pensamiento claro y coherente
- Evidencia de reflexi贸n cr铆tica profunda

## 驴Qu茅 Sigue? An谩lisis de Concordancia entre Evaluadores/as

Despu茅s de que todas y todos hayan completado sus evaluaciones, se realizar谩 un an谩lisis de **concordancia entre evaluadores/as** (inter-annotator agreement). Este an谩lisis medir谩:

- **Concordancia exacta**: 驴Qu茅 tan frecuentemente marcaron exactamente el mismo texto como error?
- **F1 para coincidencia parcial**: 驴Qu茅 tan bien se superponen sus anotaciones cuando no son id茅nticas?
- **Kappa para concordancia de categor铆as**: 驴Qu茅 tan consistentemente categorizaron el mismo tipo de error?

### 驴Por Qu茅 Importa la Concordancia?

La concordancia entre evaluadores/as es un indicador de:
- **Calidad de las anotaciones**: Alta concordancia sugiere evaluaciones objetivas y bien fundamentadas
- **Comprensi贸n compartida**: Medida de qu茅 tan bien entienden y aplican MQM como grupo
- **reas de mejora**: Baja concordancia en ciertos tipos de errores indica necesidad de capacitaci贸n adicional

Los resultados se discutir谩n en clase y se utilizar谩n para:
- Identificar 谩reas donde el grupo necesita armonizar su comprensi贸n
- Desarrollar mejores pr谩cticas para evaluaci贸n consistente
- Mejorar la aplicaci贸n del marco MQM en futuras evaluaciones

Este proceso de medici贸n y armonizaci贸n refleja pr谩cticas profesionales reales en la industria de localizaci贸n, donde equipos de evaluadores/as deben trabajar de manera consistente para proporcionar retroalimentaci贸n 煤til y datos confiables.

## Reflexi贸n Final

Esta evaluaci贸n representa la culminaci贸n de tu aprendizaje sobre gesti贸n de calidad de traducci贸n en este curso. Has progresado desde:
- Ser evaluado/a como traductor/a
- Comprender el marco MQM te贸ricamente
- Practicar con el entorno de Label Studio
- Realizar una evaluaci贸n profesional completa

Las habilidades que desarrollasteidentificar errores sistem谩ticamente, categorizarlos con precisi贸n, y evaluar hol铆sticamenteson fundamentales para el trabajo profesional en traducci贸n, localizaci贸n y entrenamiento de sistemas de IA.

---

##  Descarga esta Actividad

Encuentra este archivo [en nuestro repositorio](https://github.com/alainamb/uic_tr18-trad-inversa-es-en/blob/main/unidad3/semana9/proyecto-evaluacion-conanp.md) y desc谩rgalo.

Para optimizar tu evaluaci贸n y reflexi贸n sobre el proceso, prueba estos prompts con tu herramienta de IA preferida:

- "Ay煤dame a desarrollar una estrategia sistem谩tica para revisar un documento completo e identificar todos los errores de traducci贸n"
- "驴C贸mo puedo distinguir entre errores reales que violan las especificaciones y preferencias personales en traducci贸n?"
- "Crea un marco para escribir comentarios 煤tiles y constructivos sobre errores de traducci贸n"
- "驴Qu茅 preguntas debo hacerme al determinar el nivel de severidad apropiado para un error de traducci贸n?"
- "Ay煤dame a reflexionar cr铆ticamente sobre mi proceso de evaluaci贸n: 驴qu茅 funcion贸 y qu茅 podr铆a mejorar?"
- "Explica c贸mo las habilidades de evaluaci贸n de calidad pueden mejorar mi trabajo como traductor/a"

---

**隆Unidad 3 Completa!** Repasa lo que has logrado en la [Conclusi贸n de la Unidad 3](../unidad3-conclusion.md)
